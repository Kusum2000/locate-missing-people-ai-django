{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import imutils\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "pathToExecutable = (\n",
    "    \"C:/Program Files/GNU Octave/Octave-7.1.0/mingw64/bin/octave-cli.exe\"\n",
    ")\n",
    "os.environ['OCTAVE_EXECUTABLE'] = pathToExecutable\n",
    "from oct2py import octave\n",
    "from detect_face import detect_face, FaceAligner\n",
    "fa = FaceAligner(desiredFaceWidth=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_imgs= ['missing/010A06.JPG','missing/010A07b.JPG','missing/010A09.JPG','missing/015A00.JPG','missing/015A01.JPG','missing/015A03.JPG',\n",
    "'missing/015A04.JPG','missing/067A14.JPG','missing/067A17.JPG',\n",
    "'missing/067A21.JPG','missing/067A23.JPG','missing/071A22.JPG', \n",
    "'missing/071A24.JPG','missing/071A27.JPG','missing/071A35.JPG',\n",
    "'missing/001A22.JPG','missing/001A28.JPG','missing/001A29.JPG',\n",
    "'missing/001A33.JPG','missing/003A47.JPG','missing/003A49.JPG',\n",
    "'missing/003A58.JPG','missing/011A15.JPG','missing/011A20.JPG',\n",
    "'missing/011A30.JPG','missing/011A34.JPG',\n",
    "'missing/WhatsApp_Image_2022-05-29_at_7.jpeg',\n",
    "'missing/WhatsApp_Image_2022-05-292.jpeg',\n",
    "'missing/WhatsApp_Image_2022-05-29_at_7.00.18_PM_2.jpeg',\n",
    "'missing/WhatsApp_Image_2022-05-28_at_1.12.11_PM.jpeg',\n",
    "'missing/WhatsApp_Image_2022-05-28_at_2.16.09_PM.jpeg',\n",
    "'missing/WhatsApp_Image_2022-05-28_at_2.14.35_PM.jpeg',\n",
    "'missing/IMG_20190404_194014.jpg','missing/IMG026.jpg',\n",
    "'missing/Photo0149.jpg']\n",
    "missing_labels= ['SanjanaTrivari_2007-03-04','SanjanaTrivari_2007-03-04','SanjanaTrivari_2007-03-04','AndyLilith_2002-09-09','AndyLilith_2002-09-09','AndyLilith_2002-09-09','AndyLilith_2002-09-09','AshinaRai_2013-09-04','AshinaRai_2013-09-04','AshinaRai_2013-09-04','AshinaRai_2013-09-04',\n",
    "'ManishPaul_2019-09-22','ManishPaul_2019-09-22','ManishPaul_2019-09-22',\n",
    "'ManishPaul_2019-09-22','AdamSingh_2016-02-28','AdamSingh_2016-02-28',\n",
    "'AdamSingh_2016-02-28','AdamSingh_2016-02-28','SushaNair_2022-02-03',\n",
    "'SushaNair_2022-02-03','SushaNair_2022-02-03','SurajSinha_2022-12-05',\n",
    "'SurajSinha_2022-12-05','SurajSinha_2022-12-05','SurajSinha_2022-12-05',\n",
    "'KeerthanaK_2022-05-22','KeerthanaK_2022-05-22','KeerthanaK_2022-05-22',\n",
    "'AnsuiyaSharma_2021-05-10','AnsuiyaSharma_2021-05-10','AnsuiyaSharma_2021-05-10','KusumRamachandra_2013-03-04','KusumRamachandra_2013-03-04','KusumRamachandra_2013-03-04',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#missing_labels.append('check')\n",
    "n_labels = len(set(missing_labels))\n",
    "print(n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SanjanaTrivari_2007-03-04\n",
      "AndyLilith_2002-09-09\n",
      "AshinaRai_2013-09-04\n",
      "ManishPaul_2019-09-22\n",
      "AdamSingh_2016-02-28\n",
      "SushaNair_2022-02-03\n",
      "SurajSinha_2022-12-05\n",
      "KeerthanaK_2022-05-22\n",
      "AnsuiyaSharma_2021-05-10\n",
      "KusumRamachandra_2013-03-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "labels_dict = dict()\n",
    "u_labels=missing_labels\n",
    "missing_labels_en= label_encoder.fit_transform(missing_labels)\n",
    "for i in range(0,len(missing_labels)):\n",
    "    if missing_labels_en[i] not in labels_dict:\n",
    "        labels_dict[missing_labels_en[i]]=missing_labels[i]\n",
    "        u_labels.append(missing_labels[i])\n",
    "        print(missing_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 'SanjanaTrivari_2007-03-04',\n",
       " 1: 'AndyLilith_2002-09-09',\n",
       " 3: 'AshinaRai_2013-09-04',\n",
       " 6: 'ManishPaul_2019-09-22',\n",
       " 0: 'AdamSingh_2016-02-28',\n",
       " 9: 'SushaNair_2022-02-03',\n",
       " 8: 'SurajSinha_2022-12-05',\n",
       " 4: 'KeerthanaK_2022-05-22',\n",
       " 2: 'AnsuiyaSharma_2021-05-10',\n",
       " 5: 'KusumRamachandra_2013-03-04'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_labels_en= label_encoder.fit_transform(u_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(\n",
    "            include_top=True,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=None,\n",
    "            input_shape=None,\n",
    "            pooling=None,\n",
    "            classes=1000,\n",
    "            classifier_activation=\"softmax\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_list,aligned_img):\n",
    "    #labels = np.zeros((1, len(missing_imgs)+1))\n",
    "    i = 0\n",
    "    images = []\n",
    "    for filename in image_list:\n",
    "        f=filename.split('/')\n",
    "        img = cv2.imread(os.path.join(dir,'content','media',f[0],f[1]))\n",
    "        img= cv2.equalizeHist(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "        \n",
    "        img= cv2.resize(img,(224,224))\n",
    "        img2 = cv2.merge((img,img,img))\n",
    "        img = img_to_array(img2)\n",
    "        images.append(img2)\n",
    "        i +=1\n",
    "    n_labels = len(set(missing_labels))\n",
    "    for i in range(0,n_labels):\n",
    "        img = cv2.equalizeHist(cv2.cvtColor(aligned_img, cv2.COLOR_BGR2GRAY))\n",
    "            \n",
    "        img= cv2.resize(img,(224,224))\n",
    "        img2 = cv2.merge((img,img,img))\n",
    "        img = img_to_array(img2)\n",
    "        images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(images):\n",
    "    with tf.device('/device:cpu:0'):\n",
    "        Flatten_list = [];\n",
    "        FC7_list = [];\n",
    "        FC6_list = [];\n",
    "        l = len(model.layers)\n",
    "        for i in range(len(images)):\n",
    "            image = images[i]\n",
    "            img = image.reshape((1, image.shape[0], image.shape[1], image.shape[2])) \n",
    "\n",
    "            keras_function = K.function([model.get_layer(index=0).input], model.get_layer(index=l - 4).output)\n",
    "            Flatten = keras_function([img])\n",
    "\n",
    "            keras_function = K.function([model.get_layer(index=0).input], model.get_layer(index=l - 3).output)\n",
    "            FC7 = keras_function([img])\n",
    "\n",
    "            keras_function = K.function([model.get_layer(index=0).input], model.get_layer(index=l - 2).output)\n",
    "            FC6 = keras_function([img])\n",
    "\n",
    "            \n",
    "            Flatten_list.append(Flatten[0])\n",
    "            FC7_list.append(FC7[0])\n",
    "            FC6_list.append(FC6[0])\n",
    "    pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=len(images)))])\n",
    "    flatten_new=pcaFuse(Flatten_list,pipeline)\n",
    "    fc7_new=pcaFuse(FC7_list,pipeline)\n",
    "    fc6_new=pcaFuse(FC7_list,pipeline)\n",
    "    t=octave.fuse(flatten_new,fc7_new,fc6_new,missing_labels_en)\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pcaFuse(layer,pipeline):\n",
    "    layer=pipeline.fit_transform(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = os.path.join(dir,'content','media','images','suraj.jpg')\n",
    "faces = detect_face(img)\n",
    "face = faces[0]\n",
    "aligned_img =  fa.align(cv2.imread(img), face['keypoints']['left_eye'], face['keypoints']['right_eye'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = models.Sequential()\n",
    "encode.add(model)\n",
    "encode.add(layers.Flatten())\n",
    "encode.add(layers.Dense(512, activation='relu'))\n",
    "encode.add(layers.Dropout(0.5))\n",
    "encode.add(layers.Dense(len(set(missing_labels))-1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.equalizeHist(cv2.cvtColor(aligned_img, cv2.COLOR_BGR2GRAY))\n",
    "            \n",
    "img= cv2.resize(img,(224,224))\n",
    "img2 = cv2.merge((img,img,img))\n",
    "img = img_to_array(img2)\n",
    "i=np.array([img])\n",
    "predict_img=encode.predict(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = preprocess(missing_imgs,aligned_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = feature_extraction(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SanjanaTrivari_2007-03-04': 3.7673311978013517, 'AndyLilith_2002-09-09': 4.147830884606251, 'AshinaRai_2013-09-04': 4.414126666682539, 'ManishPaul_2019-09-22': 4.132553413721718, 'AdamSingh_2016-02-28': 4.211225650429949, 'SushaNair_2022-02-03': 3.5266557111122627, 'SurajSinha_2022-12-05': 5.028931715920562, 'KeerthanaK_2022-05-22': 3.0430214524079258, 'AnsuiyaSharma_2021-05-10': 3.673277103799743, 'KusumRamachandra_2013-03-04': 3.7321973126991486}\n",
      "SurajSinha_2022-12-05 5.028931715920562\n"
     ]
    }
   ],
   "source": [
    "min=0\n",
    "individual_rank={}\n",
    "i=0\n",
    "for c in encoded_dataset:\n",
    "    dist = np.linalg.norm(c-predict_img)\n",
    "    if missing_labels[i] not in individual_rank:\n",
    "        individual_rank[missing_labels[i]]=dist\n",
    "    elif missing_labels[i] in individual_rank:\n",
    "        individual_rank[missing_labels[i]]+=dist\n",
    "    #print('Answer',missing_labels[i], dist)     \n",
    "    i+=1\n",
    "print(individual_rank)  \n",
    "for k,v in individual_rank.items():\n",
    "    if v>min :\n",
    "        min=v\n",
    "        result=k\n",
    "print(result,min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suraj\n",
    "Answer SushaNair_2022-02-03 1.1133775801637613\n",
    "Answer SushaNair_2022-02-03 1.0678103711951261\n",
    "Answer SushaNair_2022-02-03 1.0139145482510632\n",
    "\n",
    "Answer SurajSinha_2022-12-05 1.2290534424790167\n",
    "Answer SurajSinha_2022-12-05 1.1925012967695319\n",
    "Answer SurajSinha_2022-12-05 1.1557163813794402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "susha\n",
    "Answer SushaNair_2022-02-03 1.4152642441897598\n",
    "Answer SushaNair_2022-02-03 1.3460243265930465\n",
    "Answer SushaNair_2022-02-03 1.3142974229930382\n",
    "\n",
    "Answer SurajSinha_2022-12-05 0.9846364009483524\n",
    "Answer SurajSinha_2022-12-05 0.9431183644524782\n",
    "Answer SurajSinha_2022-12-05 0.9122814727067913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer ManishPaul_2019-09-22 1.195047598669227\n",
    "Answer ManishPaul_2019-09-22 1.1235340147159012\n",
    "Answer ManishPaul_2019-09-22 1.0894295683844024\n",
    "Answer ManishPaul_2019-09-22 1.015105884942095\n",
    "\n",
    "Answer SushaNair_2022-02-03 1.2939771655940806\n",
    "Answer SushaNair_2022-02-03 1.2357712414039108\n",
    "Answer SushaNair_2022-02-03 1.1970747858401418\n",
    "\n",
    "Answer SurajSinha_2022-12-05 0.9229741650187925\n",
    "Answer SurajSinha_2022-12-05 0.9010818062271367\n",
    "Answer SurajSinha_2022-12-05 0.8459668290123301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39a6de093090d1ffba0f4f82146e7e6dde8da8eff09a444968a8fba3b3d0ed85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gpu_enabled')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
